{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import shapiro, kstest, probplot\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.gofplots import qqplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open dataset\n",
    "df_pontuation = pd.read_csv('./datasets/pontuation.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics analysis of the variables\n",
    "df_pontuation.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dispersion plt\n",
    "# X = study_hours\n",
    "# y = pontuation\n",
    "sns.scatterplot(data=df_pontuation, x='study_hours', y='pontuation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify outliers in independent variable\n",
    "sns.boxplot(df_pontuation, y='study_hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify outliers in dependent variable\n",
    "sns.boxplot(df_pontuation, y='pontuation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify correlation - Pearson\n",
    "sns.heatmap(df_pontuation.corr('pearson'), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify correlation - Spearman (non-linear)\n",
    "sns.heatmap(df_pontuation.corr('spearman'), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of variables\n",
    "sns.displot(df_pontuation, x='study_hours')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide training and test\n",
    "# when there is just one feature, it is necessary to reshape the array\n",
    "X = df_pontuation.study_hours.values.reshape(-1, 1)\n",
    "y = df_pontuation.pontuation.values.reshape(-1, 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model to be trained\n",
    "reg_model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "reg_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the equation of the model\n",
    "# y = ax + b\n",
    "print(\"The equation of y = {:4f}x + {:4f}\".format(reg_model.coef_[0][0], reg_model.intercept_[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate Model - Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict values based on tests dataset\n",
    "y_pred = reg_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metric R-squared or Determination Coefficient\n",
    "# 0 to 1. Represents the percentage of the dependent variable that is explained by the independent variable\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Regression tries to minimize the sum of the squared errors\n",
    "# Calculate metric Mean Absolute Error (MAE) - difference between the real value and the predicted value\n",
    "# MAE = Media(y_test - y_pred)\n",
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metric Mean Squared Error (MSE) - difference between the real value and the predicted value\n",
    "# MSE = Media(y_test - y_pred)^2\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metric Root Mean Squared Error (RMSE) - difference between the real value and the predicted value\n",
    "# MSE = Raiz(Media(y_test - y_pred)^2)\n",
    "mean_squared_error(y_test, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphical analysis of the model\n",
    "x_axis = range(len(y_test))\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=x_axis, y=y_test.reshape(-1), color='blue', label='Real Values')\n",
    "sns.scatterplot(x=x_axis, y=y_pred.reshape(-1), color='red', label='Predicted Values')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate residues\n",
    "# difference between the real value and the predicted value\n",
    "residues = y_test - y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize residues (standardization)\n",
    "# For each set element (X - media) / standard deviation\n",
    "from scipy.stats import zscore\n",
    "\n",
    "residues_std = zscore(residues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify linearity of model:\n",
    "  # If residues are between -2 and +2 (in standard deviation), the model is linear\n",
    "  \n",
    "# Verify homogeneous variance of model (Homocedasticity):\n",
    "  # If values are around 0, the model is homocedasticity, otherwise, if it has any pattern, there is heterocedasticity\n",
    "\n",
    "sns.scatterplot(x=y_pred.reshape(-1), y=residues_std.reshape(-1))\n",
    "plt.axhline(y=0, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if residues follow a normal distribution\n",
    "# QQ (Quantile-Quantile) Plot\n",
    "import pingouin as pg\n",
    "\n",
    "pg.qqplot(residues_std, dist='norm', confidence=0.95)\n",
    "plt.xlabel('Theoretical Quantiles')\n",
    "plt.ylabel('Residues in Standard Scale')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normality test - Shapiro-Wilk\n",
    "# H0: residues follow a normal distribution\n",
    "# H1: residues do not follow a normal distribution\n",
    "# If p-value < 0.05, reject H0, otherwise, do not reject H0\n",
    "stat_shapiro, p_value = shapiro(residues.reshape(-1))\n",
    "print(\"Test stastistics: {} and P-Value: {}\".format(stat_shapiro, p_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normality test - Kolmogorov-Smirnov\n",
    "# H0: residues follow a normal distribution\n",
    "# H1: residues do not follow a normal distribution\n",
    "# If p-value < 0.05, reject H0, otherwise, do not reject H0\n",
    "stat_ks, p_value_ks = kstest(residues.reshape(-1), 'norm')\n",
    "print(\"Test stastistics: {} and P-Value: {}\".format(stat_ks, p_value_ks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model.predict([[30.4]])1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting reverse - based on pontuation, predict study hours\n",
    "# y = ax + b\n",
    "# y - b = ax\n",
    "# (y - b) / a = x\n",
    "# x = (y - b) / a\n",
    "(600 - reg_model.intercept_[0]) / reg_model.coef_[0][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notes_prediction-LBiznFJT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
